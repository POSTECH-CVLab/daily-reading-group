# 2021 August
## Full List of papers - updated weekly
* GIRAFFE : Representing Scenes as Compositional Generative Neural Feature Fields ([진오](./summary/jinoh_1.md))
* Closed-From Factorization of Latent Semantics in GANs ([진오](./summary/jinoh_3.md))
* GANSpace: Discovering Interpretable GAN Controls ([진오](./summary/jinoh_4.md))
* Contrastive Learning for Unpaired Image to Image Translation ([진오](./summary/jinoh_6.md))
* Momentum Contrast for Unsupervised Visual Representation Learning ([진오](./summary/jinoh_7.md))
* CORAL - Colored structural representation for bi-modal place recognition ([강희](./summary/kanghee_2.md))
* Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments ([강희](./summary/kanghee_3.md))
* Semantic Graph Based Place Recognition for 3D Point Clouds ([강희](./summary/kanghee_5.md))
* HRegNet : A Hierarchical Network for Large-scale Outdoor LiDAR Point Cloud Registration ([강희](./summary/kanghee_6.md))
* NeuroMorph : Unsupervised Shape Interpolation and Correspondence in One Go ([강희](./summary/kanghee_12.md))
* KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control ([강희](./summary/kanghee_26.md))
* Unsupervised Learning of Probably Symmetric Deformable 3D objects from Images in the Wild ([민국](./summary/minguk_1.md))
* Emerging Properties in Self-Supervised Vision Transformers ([민국](./summary/minguk_2.md))
* Omni-GAN: On the Secrets of cGANs and Beyond ([민국](./summary/minguk_3.md))
* Unsupervised Learning of Visual Features by Contrasting Cluster Assignments ([민국](./summary/minguk_4.md))
* Denosing Diffusion Probabilistic Models ([민국](./summary/minguk_5.md))
* Diffusion Models beat GANs on Image Synthesis ([민국](./summary/minguk_6.md))
* Denoising Diffusion Implicit Models ([민국](./summary/minguk_7.md))
* On the difficulty of training Recurrent Neural Networks ([승욱](./summary/seungwook_2.md))
* Spatial-Temporal Transformer for Dynamic Scene graph Generation ([승욱](./summary/seungwook_3.md))
* A Closer Look at Memorization in Deep Networks ([승욱](./summary/seungwook_4.md))
* An Empirical Study of Training Self-Supervised Vision Transformers ([승욱](./summary/seungwook_5.md))
* End-to-End Object Detection with Transformers ([승욱](./summary/seungwook_6.md))
* IDM: An intermediate Domain Module for Domain Adaptive Re-ID ([승욱](./summary/seungwook_9.md))
* MDETR - Modulated Detection for End-to-End Multi-Modal Understanding ([승욱](./summary/seungwook_10.md))
* Recurrent Parameter Generators ([승욱](./summary/seungwook_11.md))
* RobustNet: Improving Domain Generalization in Urban-Scene segmentation via Instance Selective Whitening ([승욱](./summary/seungwook_12.md))
* DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification ([승욱](./summary/seungwook_13.md))
* How to avoid machine learning pitfalls: A guide for academic researchers ([승욱](./summary/seungwook_16.md))
* How to train your ViT? Data, Augmentation, and Regularization in Vision Transformers ([승욱](./summary/seungwook_17.md))
* Generating Long Sequences with Sparse Transformers (a.k.a Sparse Transformer) ([승욱](./summary/seungwook_18.md))
* PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space ([승욱](./summary/seungwook_19.md))
* Relational Embedding for Few-shot Classification ([승욱](./summary/seungwook_20.md))
* Mobile-Former: Bridging MobileNet and Transformer ([승욱](./summary/seungwook_23.md))
* Do Vision Transformers See like Convolutional Neural Networks? ([승욱](./summary/seungwook_24.md))
* FastFormer: Additive Attention is All you need ([승욱](./summary/seungwook_25.md))
* PonderNet: Learning to ponder ([승욱](./summary/seungwook_26.md))
* PoinTr: Diverse Point Cloud Completion with Geometry-Aware Transformers ([승욱](./summary/seungwook_29.md))
* Polygonal Building Extraction by Frame Field Learning ([수현](./summary/suhyeon_1.md))
* Stand-Alone Self-Attention in Vision Models ([수현](./summary/suhyeon_2.md))
* Scaling Local Self-Attention for Parameter Efficient Visual Backbones ([수현](./summary/suhyeon_3.md))
* Where and What ? Examining Interpretable Disentangled Representations ([수현](./summary/suhyeon_4.md))
* PackIt: A virtual Environment for Geometric Planning ([수현](./summary/suhyeon_5.md))
* Non-local Neural Networks ([수현](./summary/suhyeon_9.md))
* FaceNet: A Unified Embedding for Face Recognition and Clustering ([수현](./summary/suhyeon_10.md))
* Sampling Matters in Deep Embedding Learning ([수현](./summary/suhyeon_11.md))
* Wasserstein gan ([수현](./summary/suhyeon_12.md))
* Relational recurrent neural networks ([수현](./summary/suhyeon_13.md))
* A simple neural network module for relational reasoning ([수현](./summary/suhyeon_17.md))
* Relation Networks for Object Detection ([수현](./summary/suhyeon_18.md))
* NeRD: Neural 3D Reflection Symmetry Detector ([우현](./summary/woohyeon_2.md))
* Scene Representation Networks: Continuous 3D-Structure-Aware Neural Scene Representations ([우현](./summary/woohyeon_3.md))
* StarGAN v2: Diverse Image Synthesis for Multiple Domains ([우현](./summary/woohyeon_4.md))
* Twin Auxiliary Classifier GAN ([우현](./summary/woohyeon_5.md))
* ACE: Ally Complementary Experts for Solving Long-Tailed Recognition in One-Shot ([우현](./summary/woohyeon_6.md))
* BIGRoC: Boosting Image Generation via a Robust Classifier ([우현](./summary/woohyeon_9.md))
* End-to-End Object Detection with Transformers ([우현](./summary/woohyeon_10.md))
* f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization ([우현](./summary/woohyeon_11.md))
* InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets ([우현](./summary/woohyeon_12.md))
* Neural Discrete Representation Learning ([우현](./summary/woohyeon_13.md))
* Pixel Recurrent Neural Networks ([우현](./summary/woohyeon_14.md))
* Few-Shot Unsupervised Image-to-Image Translation ([우현](./summary/woohyeon_15.md))
* Diverse Image Generation via Self-Conditioned GANs ([우현](./summary/woohyeon_16.md))
* Conditional Image Generation with PixelCNN Decoders ([우현](./summary/woohyeon_17.md))
* Auto-Encoding Variational Bayes ([우현](./summary/woohyeon_23.md))
* NICE: Non-linear Independent Components Estimation ([우현](./summary/woohyeon_24.md))
* Density Estimation using RealNVP ([우현](./summary/woohyeon_25.md))
* Group Equivariant Convolutional Networks ([우현](./summary/woohyeon_26.md))
* Steerable CNNs ([우현](./summary/woohyeon_27.md))
* Putting NeRF on a Diet: Semantically Consistent Few-Shot View Synthesis ([윤우](./summary/yoonwoo_3.md))
