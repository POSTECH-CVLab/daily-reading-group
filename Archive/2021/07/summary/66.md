# GNeRF: GAN-based Neural Radiance Field without Posed Camera
### Author Information
#### Summarized by Jinoh Cho
---

**Task** : Novel View Synthesis using GAN-based NeRF without Posed Camera

**Motivation :**
 
Original NeRF heavily rely on accuarte camera pose annotated images to train.
 
Few of NeRF's follow-ups try to optimize NeRF model without camera pose. But those methods works well on foward facing scenes and relatively short camera parameters.
 
**Contribution:** \
Propose a novel two-phases end to end framework using GAN to solve NeRF's critical problem.
 
Proposed algorithm perform well in the challenging scenes where COLMAP-based NeRF(Original NeRF trained with well annoated camera pose images) completely fail due to challenges such as repeated patterns, low textures, image with noise, and even with extreme case when the input views are a collection of gray masks.
 
Using this methods we can predict new poses of images belonging to same scene thrugh the trained inversion network without tedious per-scene pose estimation (COLMAP-like methods) or time-consumming gradient based-optimization(iNeRF and NeRF--)

**Method :**
 
Proposed pipeline learns the radiance fields and camera poses jointly in two phases. In phase A, they randomly sample poses from a predefined poses sampling space and generate corresponding images with the NeRF (G) model. The discriminator (D) learns to classify real and fake image patches. The inversion network (E) takes in the fake image patches and learns to output their poses. Then, with the inversion network’s parameters frozen, they optimize the pose embeddings of real images in the dataset. In phase B, we utilize the photometric loss to refine radiance fields and pose embeddings jointly. They follow a hybrid and iterative optimization strategy of the pattern ’A → AB. . . AB → B’ in the training process. 
 
**Weakness :** 
 
제안한 방법을 통해서 estimate한 pose가 reliable한 keypoint가 충분히 많은 상황에서 COLMAP을 사용하여 pose estimation한 것 보다는 정확하지 않다.
 
camera pose sampling distribution이 true distribution과 상당히 다른 경우에 어렵다(?)라고 써져 있는데 그러면 camera pose distribution을 알아야 되는 것이 아닌가(?) 그럼 image set에 대한 카메라 포스를 알아야 하는 것이 아닌가?
 
다른 베이스 라인 실험 예를 들어 NeRF-- 실험 결과가 더 있었으면 좋을 것 같다. 예를 들어 nerf--는 안되는데 이 방법이되는 경우 등?(실험 부재) 
 
**Strong :** 
 
COLMAP을 사용할 수 없는 상황(low textures, repeated patterns, noised image)에서는 결국 calibrating을 할 수 없어서 기존 NeRF를 사용하기 어려운데 이 방법을 사용하면 정확한 카메라 pose 없이 NeRF를 사용할 수 있어서 좋은 방향의 논문인 것 같다.