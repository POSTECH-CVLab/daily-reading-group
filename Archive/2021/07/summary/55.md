# MinkLoc++ : Lidar and Monocular Image Fusion for Place Recognition
### Author Information - IJCNN 2021
#### Summarized by Kanghee Lee 
---

**Task** : Place recognition with two modalities (RGB image, point cloud)

 

**Motivation** : two modalities로 학습시키는게 one modality로 학습한 것보다 성능이 낮아진다. (caused by different susceptibility to overfitting of two networks(=Image feature extraction, pcd feature extraction)

**Contribution** : 

1) two modality에 기반한 discriminative multimodal global descriptor제안

2) one modality가 심하게 overfitting되면서 생기는 dominating modality problem을 효율적으로 해결

**Network** :
PCD descriptor extraction network와 Image descriptor extraction network로 구성됨.

1) PCD descriptor extraction network : 이전 논문인 MinkLoc의 구조에 ECA channel attention layer를 추가함.
MinkLoc구조는 pcd를 Sparse tensor로 만든 후 Minkowski convolution을 사용하여 spatial resolution을 낮추는데 마지막에 transposed conv layer 1개를 통해 receptive field가 크면서 동시에 resolution이 높은 feature를 만든다. 이렇게 만들어진 local descriptor에 GeM pooling을 통해 k size global descriptor를 만든다.
2) Image descriptor extraction network : pre-trained ResNet18의 first four bloks를 통해 local descriptor를 뽑고 마찬가지로 GeM pooling을 통해 k size global descriptor를 만든다.

3) Descriptor aggregation : 위에서 만들어진 두 global descriptor를 간단히 concat을 통해 2k size global desciptor를 만든다. 이렇게 간단한 방식으로 aggregation을 한 이유는 NetVLAD와 같은 복잡한 feature aggregation을 사용했을때 오히려 overfitting되어 성능이 낮아짐을 확인했기 때문이다. 관련된 ablation study에서 concat이 가장 성능이 높다.
 

**Loss**:
기존과 같이 triplet loss with hard negative mining을 사용하지만 다른 점은 final global descriptor(2k size)에만 이 loss를 적용하는 것이 아니라 global descriptor from pcd와 global descriptor from image에도 각각 해당 loss를 적용한다. 즉, final GD에 의한 triplet loss + PCD GD에 의한 triplet loss + Image GD에 의한 triplet loss를 Loss로 사용한다. 이렇게 각 unimodal descriptor에 loss를 설정함으로써 각 modality의 영향을 balancing해주었고 결국 dominating modality problem을 해결할 수 있었다.