# Few-shot Image Generation via Cross-domain Correspondence 
### Utkarsh Ojha et al., Adobe Research - CVPR 2021
#### Summarized by Woohyeon Sim

* **Few-shot Image Generation에서는 주로 over-fitting issue를 다룸. 해당 이슈는 일반적으로 data augmentation이나 large-scale의 source domain에서 pretraining한 뒤 transfer(model adaptation)하는 것으로 품**. 본 논문은 두번째 방법 기반으로 이미지가 10장 정도로 적은 극단적인 상황에서 mode collapse가 일어나지 않도록 하는 방법 제안.

* **제안한 방법 1: adaptation 전후의 임베딩간 distance distribution을 비슷하게 맞춤으로써 source domain의 diversity를 target domain으로 transfer하는 방식을 도입함**. 구체적으로는, pre-trained generator와 adapted generator 각각에서 레이어마다 다른 instance들과 cosine similarity를 구한 뒤 contrastive learning과 비슷하게 인스턴스들에 대해 softmax를 취하여 adaptation 전후의 KL-divergence를 줄이는 로스 부과.
	
* **제안한 방법2: target sample이 극히 제한된 영역에 분포할 것이라는 가정으로 "realistic" 판별 기준을 제한하는 기법 도입**. 자세히는, target 이미지 수만큼 random point만큼 뽑아 그 주변 영역은 image 단위의 discrimination을 하고, 밖은 patch 단위의 discrimination을 함.
	
* **실험 결과**: 1) source와 target domain이 관련이 있을 경우 (e.g., face <-> sketch, caricatures, painting) 같은 latent vector z에 대해서 one-to-one correspondence가 만들어짐. 관련이 적을 경우 (e.g., face <-> landscape, house, cars) part-level correspondence가 만들어짐, 2) image-level discrimination이 없으면 image quality가 떨어지고 part-level discrimination이 없으면 part-level collapse가 생김.
	
* **총평**: 흥미로운 점이 많은 논문. 언뜻보면 image-to-image translation과 비슷하게 content는 보존하면서 style은 다르게 만드는 것을 하는 것 같으나, image 단위로 adapt되는게 아닌 model 단위로 adapt된다는 점에서 크게 다름. 이미지 없이 임의의 latent vector로 곧바로 생성할 수 있다는 점이 신기하였음.
	