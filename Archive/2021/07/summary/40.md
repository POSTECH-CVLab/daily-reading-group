# On the Continuity Rotation Representations in Neural Networks
### Author Information 
#### Summarized by Yoonwoo Jeong

 
**Motivation**


	
* Previous known rotation representations are discontinuous; as a result, the neural network gets a penalty to run the rotation representations. However, directly optimizing the rotation matrix requires preservation of orthogonal property, indicating naive 3X3 matrix is not suitable for optimization.
	
* Here, we propose a representation that satisfies the continuity of representation while requiring fewer parameters than rotation matrices. We propose two representations, one with 5 parameters and the other with 6 parameters. Both of the representation shows better performance compared to previous representation, indicating the proposed representations are much suitable for neural networks.
	
* They have evaluated their representation's performance in three tasks: sanity test, 3D point cloud pose estimation test, and human body inverse kinematics test.


**Representation**

* Rather than using whole parts of the rotation matrix, it only uses $n-1$ columns. They recover the rotation matrix by the Gram-Schmidt process. As a consequence, they only use $n(n-1)$ parameters to represent any rotation matrix.
	
* One more possible reduction of this representation is done by a process called stereographic projection. However, according to the paper, this representation cannot completely recover the original matrix.


**Conclusion**

* Mathematically well-written paper but lack of description for begginer. The content in this paper is strongly related to my work. Its impact on future work is expected to be great.
	
* Mathematical derivation is fully demonstrated in the paper. However, due to my insufficient mathematical background, it was a hard paper for me.