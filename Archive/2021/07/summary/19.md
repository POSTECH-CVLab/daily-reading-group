# Per-Pixel Classification is Not All You Need for Semantic Segmentation
### Bowen Cheng et al., Facebook AI Research) - NeurIPS Submission
#### Summarized by Woohyeon Sim

* Task: image segmentation
* Main contribution:
    * outperform per-pixel classification with **mask classification**.
	* Solve semantic- and instance- segmentation in a unified manner with **fewer parameter and computation**.
* **Mask classification = image partitioning with N binary masks + classification with K category**
    * N and K do not need to be the same.
    * Binary mask is represented with mask embedding vector and obtained by dot-product with per-pixel embedding vectors.
    * Per-pixel embedding vector is CNN or transformer backbone features upsampled to original resolution.
    * Mask embedding vector is an output of transformer decoder.
    * Transformer decoder takes backbone features and learnable positional embedding as input and outputs mask embedding vector and class probability.
* **Training = cross-entropy loss after matching with gt and prediction.**
    * binary cross-entropy loss for mask prediction and categorical cross-entropy loss for classification
    * fixed matching if the number of predictions N matches the number of category label K
    * bipartite matching in general by computing assignment cost (e.g., loss)
    * mask is not mutually exclusive and can be assigned to "no object" label.

**총평**: Segmentation 문제를 하나로 통합하고 적은 파라미터와 계산량, 그리고 추가적인 학습 로스 없이 깔끔하게 푼점과 큰 성능 향상을 볼 때 segmentation의 방향은 여기에 있다고 생각함.