# Rethinking and Improving the Robustness of Image Style Transfer
### Pei Wang et al., UC San Diego) - CVPR 2021 [best paper candidate]
#### Summarized by Woohyeon Sim

* **ResNet이 VGG보다 style transfer가 잘 안되는 원인을 찾고 이를 해결한 논문**. 그 결과 ResNet계열의 아키텍쳐에서 pre-trained weight뿐 아니라 random weights에서도 VGG 못지 않게 stylization 성능이 크게 오르는 것을 보여주고, feature representation이 style transfer에서도 중요함을 보임. 또한 제안한 방법은 다른 style transfer loss와 compatible함.
* **원인 분석1 (invalid, X): ResNet은 feature에 robustness가 부족해서** 잘 안됨 ⇒ robustness가 증가되면 stylization quality는 높아지는 건 맞지만 VGG는 random weight에도 잘 되기 때문에 robusness가 직접적인 원인은 아님.
* **원인 분석2 (valid, O): ResNet으로 구한 gram matrix의 entropy가 작기 때문에 그것을 따라 학습된 style pattern도 diversity가 낮아질 수 밖에 없음** ⇒ 실험적으로 residual connection이 있으면 feature map과 gram matrix 모두 small entropy (large peak)를 갖는 것으로 관측됨. 따라서 이것을 따라가도록 학습하는 것은 특정 style pattern에 dominate 되거나 outlier sensitivity가 심해질 수 있음. 또한 style을 비슷하게 맞추는 것을 distillation관점에서도 설명할 수 있는데, distillation은 hard target을 쓰는 것이 soft target을 쓰는 것보다 수렴도 느리고 안좋음.
* **해결책 - Stylization With Activation smoothinG (SWAG).** 원인 분석 2의 distillation관점에서 봤을 때 hard target보다 soft target이 좋으므로 peaky activation을 smoothing하여 soft target으로 바꾸는 방법을 제안. 구체적으로는, 단순히 로스 구할 때 feature에 softmax를 취하는 것임. 이렇게 하면 큰 값은 작아지고 작은 값은 커져서 entropy가 커진다고함. 주의할 점은 네트워크에 softmax layer를 넣는 것이 아니어서 representation power는 그대로 유지된다는 것임. 다른 smoothing 기법, 곧 nested softmax, 0.1배 곱하는 것등이 있는데 성능은 비슷해서 간단한 softmax를 썼다고 함.
* **총평**: 실험 결과는 제안한 로스로만 바꾸면 모든 네트워크와 학습 방법에서 크게 좋아짐. 그러나 분석 방식과 제안한 방법이 크게 새로운 요소는 없어서 무엇때문에 best paper candidate이 되었는지는 모르겠음.