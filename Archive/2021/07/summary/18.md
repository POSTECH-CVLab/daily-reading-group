# TransGAN: Two Pure Transformers Can Make One strong GAN, and That Can Scale Up
### Author Information - submitted to Neurips2021
#### Summarized by Minguk Kang

```
본 논문에서는 Transformer 구조만 사용하여 처음으로 GAN학습을 성공시킨 논문입니다. 본 논문에서는 GAN 학습을 위해 Transformer를 사용해야하는 이유를 "호기심"과 local and global semantic structure를 더 잘학습하기위해라고 주장하고 있습니다. 아키텍처를 구체적으로 살펴보면,
 
먼저 z를 MLP에 태워 w \in \mathcal{R}^{H0*W0*C}를 만들어줍니다. 다음으로 이를 H0xW0xC로 reshape를 한 다음 H0*W0*C 개수의 token을 만들어주고, ViT block에 태운 다음 upsampling을 진행해주게 됩니다.

upsampling은 토큰을 합쳐 H0xW0xC의 크기로 reshape을 주게되는데, 이후에 bicubic interpolation을 통해 2H0x2W0xC spatial resolution을 늘리는 방향으로 spatial size를 키우게 되고 최종적으로 이미지를 생성하게 됩니다.

최종적인 성능은 50K 이미지를 사용하여 측정하였고, 기존의 unconditional BigGAN and StyleGAN2와 비교하여 comparable한 성능이 나온게 장점인 것 같습니다.

아쉬운 점은 Imagenet을 사용한 실험이 없었고, conditional image generation에 대한 실험이 없었다는 것 입니다. 또한, 논문에 너무 많은 양의 내용을 넣으려다보니 필요한 부분에서 디테일이 부족하다는 단점도 있는 것 같습니다.
```