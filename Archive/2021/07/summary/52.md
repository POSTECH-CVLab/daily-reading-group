# Few-shot Image Generation via Cross-domain Correspondence
### Author Information
#### Summarized by Minguk Kang
---
```
해당 논문은 k-shot (논문에서는 k=10) 이미지만 가지고 GAN을 학습시키는 방법을 다루고 있으며 방법은 아주 심플하지만 재미있는 결과를 보여주고 있습니다.
 
구체적으로, 
Large-scale dataset (source)을 사용하여 사전학습이 되어 있는 모델을 G_{s}라고 하고, 목적이 되는 데이터세트 (target_)의 분포를 근사하는 생성자를 (G_{s->t})이라고 하면, 본 연구는 G_{s}를 사용하여 G_{s->t}를 잘 학습하는 방법을 찾는 것을 목적으로 하고 있습니다. 이를 위해 논문에서는 2가지 방법을 제안했는데,
1) 소스 데이터의 이미지와 타겟 데이터의 이미지가 비슷한 attribute를 가지도록 강제하는 correspondence loss, 
ex) 소스데이터가 FFHQ이고 타겟이 모네의 그림이라면, 생성되는 모네의 그림이 소스데이터의 포즈를 가지게 강제하는 로스
구현방식) 잠재변수들을 G_{s}와 G_{s->t} 생성자에 인가하고 생성자들의 중간 피쳐들의 similarity를 계산한 후 두 similarity가 같아지도록 KL loss를 주어 강제화한다 (G^{l}_{s}과 G^{l}_{s} 사이의 유사도와 G^{l}_{s->t} 와 G^{l}_{s->t} 사이의 유사도를 일치시킴). 
2) latent분포에서 k개만큼의 anchor latent variable을 샘플링한 후 해당 latent variable에 대해서는 full image adversarial loss 그 외 나머지 공간에서 샘플링 된 latent variable에 대해서는 patch-based adversarial loss를 적용한다,
입니다.
 
비교는 여러가지 Few-shot GAN 모델들과 진행한 것으로 보이며, 모상우씨의 FreezeD역시 비교 대상에 포함됩니다.
결과는 다른 베이스라인 모델에 비해서 잘 나오는 것으로 보이며, FreezeD와 함께 사용될 수 있는 것으로 보이지만 관련 ablation은 존재하지 않네요.
 
최근 GAN 이론보다는 pre-trained된 GAN을 어떻게 활용할까에 대한 논문이 정말 많이 나오는 것 같습니다.
이상입니다.
```