# NeRF: Representation Scenes as Neural Radiance Fields for View synthesis 
### Author information
#### Summarized by Minguk Kang

```
NeRF는 X = (x,y,z)좌표와 d = (\theta, \phi) 카메라 각도를 MLP의 Input으로 주고, c = (R, G, B) 색상과 density = (\sigma)를 예측하는 뉴럴넷을 학습하는 것을 목표로합니다. 기존의 volumetric rendering은 high-dimensional 데이터의 렌더링을 하지 못했고, 랜더링 시 high-frequency features들을 잡지 못한다는 단점을 가지고 있었지만, NeRP에서는 이를 NN의 파워와 positional encoding, 그리고 hierarchical volume sampling을 통해 해결할 수 있었습니다. 

 

조금 더 세부적으로, 주어진 원점 o에서 씬을 볼 때 여러개의 ray가 생기는데 각 ray는 density가 높은 지점과 density가 낮은 지점으로 구성되어 있습니다. density가 낮은 지점은 투명한 곳으로 색상에 영향을 적게 줘야하고 density가 높은 지점은 색상에 영향을 크게 줘야합니다. 또한, 물체의 surface의 컬러만 사용하지 않은 이유는 unseen view point에서도 랜더링을 하기 위함으로, 이전의 volumetric rendering방법에서 영감을 얻어 사용되었습니다. 결과적으로 density들을 적분하여 특정 view point에서 특정 ray의 색상을 결정하게 됩니다. 하지만, 이렇게 해서는 NN을 효과적으로 학습할 수 없어 두가지 트릭을 쓰는데 첫번째는 high-frequency function을 통해 input을 조금 더 높은 차원으로 임베딩하는 positional embedding이 있고, 나머지 하나로는 density가 높은 지점에서 샘플링을 더하여 fine network를 학습하는 hierarchical sampling이 있습니다. 

 

논문을 읽으면서 글을 정말 쉽게 잘 적었다는 느낌을 받을 수 있었고, 작가가 정말 천재인게 아닌가라는 느낌을 받아서 읽는 내내 즐거웠던 논문이였던 것 같습니다.
```



