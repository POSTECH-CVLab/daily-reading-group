# Editing Conditional Radiance Fields
### Steven Liu et al.,
#### Summarized by Jinoh Cho

이번 논문은 간단하게 말하자면 Color Code와 Shape Code를 기존 NeRF의 입력 인자들 외에 추가적으로 받아서 Category Specific 하게 학습시킨 Conditional Radiance Fields를 바탕으로 새로운 로스펑션을 도입하고 네트워크를 부분적으로 학습함으로써 Edit된(Color나 Shape이 바뀐) Representation을 효과적으로 학습시킴과 동시에 고품질의 Novel View를 이미지를 렌더링한 방법을 제시한 논문입니다. (Style-GAN2를 사용한 Editing보다 더 좋은 이미지 Generation 결과를 보여줌)

 

이 논문에서 제시한 방법에 대한 제가 생각하는 컨트리 뷰션은 다음과 같습니다.


	
* Shape과 Color가 Disentangled된 Conditional Radiance Field Representation을 통해서 상대적으로 쉽게 Edit한 Representation을 할 수 있는 네트워크 구조를 제안함.
	
* 네트워크를 크게 5개 파트로 나눌 수 가 있는데 Shape을 Edit시키느냐 Color를 Edit을 시키느냐에 모델 전체를 finetuning하는 것이아닌 선택적으로 파트를 finetuning시켰고, 이를 통해서 최대한 적은 파라미터를 finetuning함으로써 시간과 이미지 품질 사이의 밸런스를 잘 맞출 수 있는 approach를 찾음.
	
* Color Edit, Shape part removal, Shape part addition 중 어느 것을 Editing 하는 가에 따라서 Regularization Loss와 함께 추가적인 로스를 잘 디자인 하였음.

제가 생각하는 눈문의 Limitation은 다음과 같습니다.


	
* 생각보다 쉬운 Editing 실험 결과만을 보여주고 있음. 좀 더 하쉬한 Editing을 할 수 있게 되면 좋겠음. 거의 Synthetic 데이터에서만 결과를 보여주는 데 좀 더 Realistic 데이터셋으로 확장가능하면 좋을 것 같음.
	
* Color를 건들이느냐 Shape을 지우거나 추가하거냐에 따라서 너무 Explicit하게 로스를 디자인하고 있음. 좀 더 General한 로스 디자인이 있으면 좋을 것 같음.
	
* Test time optimization(finetuning 과정이 필요하여) interactive한 Editing에는 한계가 있음. 특히, shape editing에서 finetuning 시간이 1분정도로 오래 걸림.