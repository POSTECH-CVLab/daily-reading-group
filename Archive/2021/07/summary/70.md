# Nex: Real-time View Synthesis with Neural Basis Expansion 
### Suttisak Wizadwongsa et al., VISTEC Thailand - CVPR 2021 Oral
#### Summarized by Woohyeon Shim
---

**Task**: learning a 3D representation that can render novel views based on enhancements of multiplane image (MPI) representation.
	
	
	
**MPI**: a 3D scene representation that consists of a collection of D planar images

	
⇒ each has H × W × 4 dimension, consisting of RGB and alpha transparency values.

	
⇒ images are scaled and placed equidistantly either in the depth space (for bounded close-up objects) or inverse depth space (for scenes that extend out to infinity) along a reference view.

	
⇒ rendering can be done with a homography warping to the target view and applying the composite operator over plane images.
	
	
	
**Strengths of MPI:**

	
⇒ allows photo-realistic and real-time synthesis.

	
⇒ effective for rendering complex scene with occlusions, thin structures, or planar reflections.
	
	
	
**Weaknesses of MPI:**
	
⇒ MPI can only model diffuse or Lambertian surfaces, whose colors appear constant regardless of the viewing angle.

	
⇒ Objects in real-world are non-Lambertian (e.g.,ceramic plate and a glass table) and exhibit view-dependent effects such as reflection and refraction.

	
⇒ Reconstructing these objects with an MPI can make the objects appear unrealistically dull without reflections or even break down completely due to the violation of the brightness constancy assumption used for matching invariant and 3D reconstruction.
	
	
	
**Contribution**: handling non-Lambertian surfaces (e.g., sharp highlights) that only appear in one distinct location in each input view.
	
	
	
**Method**:

	
⇒ **Parameterize each color value** as a function of the viewing direction v = (vx, vy, vz).
* direct mapping is possible but not generalizable to unobserved angles.
	

	
⇒ Approximate this function with a linear combination of learnable basis functions {Hn(v) : R3 → R} over the spherical domain described by vector v.
* this step is called as neural basis expansion on the pixel representation.
		
* linear combination is done with the following parameters per pixel: α, k0, k1, . . . , kN (an alpha transparency value, base color k0, and view-dependent reflectance coefficients k1...kn).
		
* all parameters are predicted with MLP except "base color" k0, which is stored explicitly as a learnable parameter for reproducing details in fewer iterations. this design is inspired from the fact that fine detail or high-frequency content tends to come from the surface texture itself and not necessarily from a complex scene geometry.
	

	
⇒ **Learnable basis functions** is modeled by additional MLP given normalized viewing direction.

* common choices for basis function include Fourier’s basis or Taylor’s basis and Spherical harmonics to model complex reflectance properties.
		
* one shortcoming of these “fixed” basis functions is that in order to capture high-frequency changes within a narrow viewing angle, such as sharp specular highlights, the number of required basis functions can be very high.
		
* but, a lot of versions of alternative basis function can be learned by the learnable basis functions the same number of coefficients.
	

	
⇒ **Computing coefficients for all pixel** for all planes can be expensive; use a **coefficient sharing scheme where every M planes** will share the same coefficients, but not the alphas.

	
⇒ Finally, to optimize our model, we evaluate the two MLPs to obtain the implicit parameters, render an output image, and compare it to the ground-truth image from the same view. We use **reconstruction losses for training.**
	
	
	
**Experiments**

	
⇒ use 192 planes for MPI.

	
⇒ mlp for predicting per-pixel parameters given the pixel location.
	
* Input: positional encoding (56 dim. in total: 20 for x, y and 16 for plane depth)
		
* Network: 6 fully-connected Leaky ReLU layers
	

	
⇒ mlp for predicting all global basis functions given the viewing angle

	

		
* Input: positional encoding (18 dim. in total: 12 for vx, 6 for vy)
		
* Network: 3 fully-connected Leaky ReLU layers
	

	
⇒ evaluated on more challenging environment showing reflection and refraction from the object (newly introduced dataset by the authors)

	
⇒ comparable or better performance than NeRF with 1000x faster inference speed.
	
	
	
**Limitations** (inheritted from MPI):

	
⇒ Viewing MPI from an angle too far away from the center, there will be "stack of cards" artifact.

	
⇒ Training MPI may require a higher number of input views to replicate view-dependent effects.
	
	
	
**총평**: MPI representation을 factorize함으로써 view dependent modeling을 efficient하게 한 논문. 기술적으로 새로운건 없어보이지만 인접한 분야의 개념을 접목시킨 것은 높이 평가할 수 있을 것 같음. MPI는 light field rendering에서 가져온 개념이라는데 다른 3D representation에 대해서도 비슷한 과정을 거칠 수 있다고함. 시도해보면 좋을 것 같음.