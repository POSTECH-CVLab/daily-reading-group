# SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud based Place Recognition
### Yan XIa et al., Technical University of Munich, Beijing Institute of Technology - CVPR2021 Oral
#### Summarized by Seungwook Kim

**Main task**: Scene Recognition (Point Cloud retrieval) - Given query point cloud, identify the closest point cloud via global descriptor

**Main novelties**: New method of global descriptor generation, New metric learning loss for retrieval
 
**Global descriptor generation**: Local descriptor generation + Aggregation
	
* **Local descriptor**: Following PointSIFT, gathers local information of each point from eight orientations (8 nearest neighbours, each in separate octants) using convolution
	
* Identify "Long-range feature dependency" using self-attention
	
* Finally aggregated using NetVLAD Layer to a single global descriptor
	
* NOTE: Previous descriptors failed to identify "long-range feature dependencies"

New metric learning loss: Hard Positive Hard Negative quadruplet loss
* Not very different from the original quadruplet loss (CVPR 2017)
* Using Hardest Positive & Hardest negative, tweaking margin parameters
	
* The loss formulation is not theoretically justified - which seems to be a major weakness.
	* BUT very effective empirically, very curious why

Achieves SoTA on all 4 conventional point-cloud based scene recognition datasets
 
**총평:** PointSIFT, Self-Attention, Novel(?) Metric learning loss를 잘 혼합한 논문.
엄청 오리지널한 아이디어는 없지만, 존재하는 여러 기법들을 처음으로 place recognition에 적용해본 (즉, novel combination) 논문이라 읽기도 편하고 이해하기도 쉽다.