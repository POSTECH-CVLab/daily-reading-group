# NERF Research Directions
### -
#### Summarized by Yoonwoo Jeong
---

NeRF의 경우 기존의 3D rendering이 가지고 있던 문제들을 지적하며 새로운 데이터 representation으로 떠오르게 되었습니다. 특히, view-dependent한 encoding을 큰 작은 memory budget으로 가능하게 하여, 조금 더 realistic한 rendering이 가능해져, novel view synthesis에서 높은 성능을 보여주었습니다. 하지만 NeRF의 경우 여러 가지 한계점을 많이 가지고 있는데, 후속작들은 이런 한계점을 지적하며 NeRF를 발전시킵니다.

**1.느린 inference time**

보통의 rendering 모델이 training time이 오래 걸리는 것은 약간의 inconvenience 정도로 이해할 수 있는 반면, inference time이 느리다는 것은 큰 문제로 작용합니다. 실제 NeRF는 하나의 이미지를 rendering 할 때에 정말 많은 MLP forwarding을 필요로 하는데, 이에 따라 400X400 의 이미지를 rendering 하는데에 5분 정도나 소요되는 문제가 있습니다. 

 

이에 대해서 크게 2가지의 접근이 제안되고 있습니다. 

**1)NeRF의 MLP를 분할하여 작은 network들을 학습하는 방법**

	
* **DeRF: Decomposed Radiance Fields (CVPR21)**
    * Scene을 decompose하여 각각 rendering 하는 방법. Scene을 rendering하는 network의 topology를 고려하여 가장 앞에 있는 네트워크로 랜더링
	
* **KiloNeRF: Speeding up Neural Radiance Fields with Thousands of Tiny MLPs**
	* 하나의 큰 MLP (NeRF network)를 학습하여 이를 1000개의 작은 MLP로 distillation을 시킴. 작은 MLP를 사용하기 때문에, forward 속도가 많이 빨라진다. (NSVF에서 사용하는 Early Ray Termination

**2)Voxel을 이용하여 속도를 증진**

* **NSVF: Neural Sparse Voxel Fields**
	* NeRF를 똑같이 학습하되, volume density가 낮은 voxel들을 coarse-to-fine으로 volume density가 낮은 위치들을 pruning 해가며 volume density가 낮은 부분은 랜더링 하지 않음. Early Ray Termination을 이용하여 rendering을 가속함. 
	
* **Baking Neural Radiance Fields for Real-time View-synthesis**
	* 현재까지 나온 논문 중에 가장 빠른 모델로 알려져 있습니다. pre-cmputed 된 feature를 저장하고, view-dependency를 encoding하는 network의 크기는 작게 설정하여, real-time inference가 가능하도록 한 모델입니다. 


 

**2. 느린 training time**

NeRF는 씬마다 모델을 각각 학습해야한다는 문제점도 있습니다. 그래서 한 씬마다 2일 정도의 시간을 투자하여 학습을 진행하는데, 이 부분에 대해 transferability 를 높이는 방향으로도 논문이 제안됩니다. 


	
* **pixelNeRF: Neural Radiance Fields from One of Few Images**
	* 2D 에서 학습된 image feature를 이용하여 적은 이미지로도 NeRF를 학습. 다른 씬으로의 학습이 빠르다는 장점이 있음.
	
* **Stereo Radiance Fields**
	* NeRF가 3D model을 이용하여 color를 학습하는 것에 반해, SRF는 2D에서 image들 간의 correspondence를 implicit 하게 encoding 하여 novel view를 rendering 한다. 기존의 SfM에서 사용하던 방법과 NeRF의 아이디어를 결합한 논문. 적은 이미지로도 학습이 잘 되며, training 속도도 빠르다.(30분 정도) 


 

**3.Robustness Issue**

NeRF는 실제로 학습이 잘 되지 않습니다. Lighting condition에도 제안을 많이 받아, internet photo collection 같은 부분에서는 어려움을 겪습니다. 또한 forward-facing scene들에 대해서만 학습이 잘 되기 때문에, 360도로 돌려가며 찍은 씬들에서는 랜더링에 문제를 겪습니다.


	
* **NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections**
	* NeRF를 internet에서 모은 사진들 (noise가 굉장히 많음, 계절도 다름)을 이용해서 NeRF를 학습합니다. Transient한 부분과 static한 부분을 각각 측정하여, realistic한 모델을 만드는 데에 성공합니다. 
	
* **NeRF++: Analyzing and Improving Neural Radiance Fields**
	* NeRF의 경우 실제 object의 depth의 범위에 대해서 지정을 해줘야합니다. 이에 대해서 real-scene에서는 background의 depth를 지정해주기가 정말 어렵습니다. NeRF++는 background와 foreground를 분리하여 rendering하여 랜더링 성능을 올렸습니다. 


 

**4.Camera Calibration**

제가 실제 진행한 연구와 유사한 방향인데, NeRF라는 모델이 결국 씬에 overfit을 얼마나 잘 하는 지가 중요한 연구이다보니, camera 정보가 정말 중요합니다. 그래서 이러한 문제를 다룬 논문들이 있습니다. 


	
* **iNeRF: Inverting Neural Radiance Fields for Pose Estimation**
	* NeRF로 학습된 이미지를 이용하여, pose를 역으로 추적하는 inverse problem을 소개합니다. 실제 inverse problem을 통해 얻어진 camera information으로 다시 학습할 경우 성능이 상승한다는 점이 흥미롭습니다.
	
* **NeRF--: Neural Radiance Fields without Known Camera Parameters**
	* Camera parameter가 주어지지 않았을 때, 단순하게 nerf의 camera parameter도 joint하게 학습하여 원래의 NeRF와 유사한 성능을 내는 논문입니다. 
	
* **Self-calibrating Neural Radiance Fields**
	* Projected Ray Distance 라는 loss를 제안하여, camera parameter가 가지는 non-linear distortion을 학습하는 논문입니다. Fish-eye lens로 촬영한 NeRF data도 제안합니다.


**5.Dynamic Rendering**

또한 최근 연구로는 dynamic한 object에 대해서도 학습을 시도합니다. 


	
* **D-NeRF: Dynamic Neural Radiance Fields**
	* 처음으로 dynamic한 object에 대해 학습을 성공한 논문입니다. t라는 시간 변수를 같이 input으로 받아, \delta x 를 학습하여 object의 부분이 이동한 양을 같이 학습합니다 그리고 학습된 위치에서 ray를 가져옵니다. 
	
* **DCTNeRF: Neural Trajectory Fields for Dynamic Novel View Synthesis**
  * 아직 못 읽어봤습니다. 