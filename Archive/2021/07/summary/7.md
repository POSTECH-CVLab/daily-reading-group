# Unsupervised Learning of Dense Visual Representations
### Pedro O. Pinheiro et al., Element AI (Neurips2020))
#### Summarized by Woohyeon Sim

* **Pixel-level dense representation으로 contrastive Learning을 한 논문.** pixel-level contrastive learning은 pixel-level variation을 유지하면서 contrastive learning을 하기 때문에 intrinsic spatial structure을 보존해야하는 dense prediction task에 유리하다고 가정할 수 있고 검증을 함.
* **View간 matched pair의 similarity는 높이고 non-matched pair는 줄임.** matching은 geometric augmentation으로 사전에 설정하며 positive pixel은 32개로 random하게 지정. negative pixel는 representative set만 MoCo 스타일로 dynamic dictionary에 저장해서 불러오며 같은 이미지의 다른 pixel로 설정하면 실패하여서 다른 이미지의 pixel로 설정함. 아키텍쳐는 FPN으로 encoder-decoder 구조 채택하며 image(224x224)의 1/4 크기(56x56)로 작업.
* **실험 결과 1 - feature representation 곧바로 평가**: linear layer 붙여 곧바로 semantic segmentation, depth estimation서 평가함. 추가로 embeding space의 NN으로 mask propagation하여 VOS에서도 평가함. 결과는 MoCo 대비 아주 크게 향상됨 (대략 10%)
* **실험 결과 2 - fine tuning:** 제안한 방법은 encoder와 decoder 모두 initialize할 수 있음. 결과는 sementic segmentation, depth estimation에서 full data는 MoCo와 비슷하고 데이터가 적어질수록 성능 차이가 커짐, object detection, instance segmentation, keypoint detection에서는 MoCo와 각각 0.2%씩 잘함. ImageNet pretrained와 비교했을 때는 모든 테스크에서 잘하거나 비슷함.
* 총평: geometric augmentation으로 self-supervision을 만든 뒤, 순전히 local feature로만 학습한 논문. 아이디어는 그럴듯 하나 앞의 논문 대비 성능은 낮은데 global feature를 사용하지 않아서 그런게 아닐까 싶음.