# 2021 July
## Full List of papers

* Baking Neural Radiance Fields for Real-Time View Synthesis ([Link](./summary/1.md))
* NeRF: Representation Scenes as Neural Radiance Fields for View synthesis ([Link](./summary/2.md))
* A Random CNN Sees Objects: One Inductive Bias of CNN and Its Applications ([Link](./summary/3.md))
* PixelNerf: Neural Radiance Fields from One or Few Images ([Link](./summary/4.md))
* Hypercorrelation Squeeze for Few-Shot Segmentation ([Link](./summary/5.md))
* Dense Contrastive Learning for Self-Supervised Visual Pre-Training ([Link](./summary/6.md))
* Unsupervised Learning of Dense Visual Representations ([Link](./summary/7.md))
* Neural Reprojection Error: Merging Feature Learning and Camera Pose Estimation ([Link](./summary/8.md))
* Few-shot Image Generation via Cross-domain Correspondence ([Link](./summary/9.md))
* EfficientDet: Scalable and Efficient Object Detection ([Link](./summary/10.md))
* Depth-supervised NeRF: Fewer Views and Faster Training for Free ([Link](./summary/11.md))
* Occupancy Networks - Learning 3D Reconstruction in Function Space ([Link](./summary/12.md))
* Rethinking and Improving the Robustness of Image Style Transfer ([Link1](./summary/13.md), [Link2](./summary/33.md))
* RepVGG: Making VGG-style ConvNets Great Again ([Link](./summary/14.md))
* ViTGAN: Training GANs with Vision Transformers ([Link](./summary/15.md))
* GIRAFFE: Representing Scene As Compositional Generative Nerual Feature Fields ([Link1](./summary/16.md), [Link2](./summary/25.md), [Link3](./summary/67.md))
* kiloNeRF ([Link](./summary/17.md))
* TransGAN: Two Pure Transformers Can Make One strong GAN, and That Can Scale Up ([Link](./summary/18.md))
* Per-Pixel Classification is Not All You Need for Semantic Segmentation ([Link](./summary/19.md))
* Residual Network Behave like ensembles of Relatively Shallow Networks ([Link](./summary/20.md))
* D-NeRF: Neural Radiance Fields for Dynamic Scenes ([Link](./summary/21.md))
* SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud based Place Recognition ([Link](./summary/22.md))
* MCL-GAN: Generative Adversarial Networks with Multiple Specialized Discriminators ([Link](./summary/23.md))
* NeRF--: Neural Radiance Fields Without Known Camera Parameters ([Link](./summary/24.md))
* Stereo radiance fields ([Link](./summary/26.md))
* Weakly-supervised physically Unconstrained Gaze Estimation ([Link](./summary/27.md))
* Convolutional Occupancy Networks ([Link](./summary/28.md))
* Generative Multi-Adversarial Networks ([Link](./summary/29.md))
* GRAF: Generative Radiance Fields for 3D-Aware Image Synthesis ([Link1](./summary/30.md), [Link2](./summary/31.md))
* Editing Conditional Radiance Fields ([Link1](./summary/32.md), [Link2](./summary/42.md))
* Swapping Autoencoder for Deep Image Manipulation ([Link](./summary/35.md))
* divco diverse conditional image synthesis via contrastive generative adversarial network ([Link](./summary/36.md))
* Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments ([Link](./summary/37.md))
* ChannelPruning for Accelerating Very Deep Neural Networks ([Link](./summary/38.md))
* CorrNet3D : Unsupervised End-to-end Learning of Dense Correspondence for 3D point clouds ([Link](./summary/39.md))
* On the Continuity Rotation Representations in Neural Networks ([Link](./summary/40.md))
* Anycost GANs for Interactive Image Synthesis and Editing ([Link](./summary/41.md))
* Indoor Visual Localization with Dense Mathing and View Synthesis ([Link](./summary/43.md))
* NERF Research Directions ([Link](./summary/44.md))
* Taming Transformers for High-Resolution Image Synthesis ([Link](./summary/45.md))
* ShaRF: Shape-conditioned Radiance Fiedls from a Single View ([Link](./summary/46.md))
* Learning Deep Features for Discriminative Localization ([Link](./summary/47.md))
* cGANs with Auxiliary Discriminative Classifier ([Link](./summary/48.md))
* Nerfies: Deformable Nerual Radiance Fields ([Link](./summary/49.md))
* Correlated Input-Dependent Label Noise in Large-scale Image Classification ([Link](./summary/50.md))
* Playable Video Generation ([Link](./summary/51.md))
* Few-shot Image Generation via Cross-domain Correspondence ([Link](./summary/52.md))
* A Simple Framework for Contrastive Learning of Visual Representations ([Link](./summary/53.md))
* On Buggy Resizing Libraries and Surprising Subtleties in FID Calculation ([Link](./summary/54.md))
* MinkLoc++ : Lidar and Monocular Image Fusion for Place Recognition ([Link](./summary/55.md))
* KeypointDeformer: Unsupervised 3D Keypoint DIscovery for Shape Control ([Link](./summary/56.md))
* High-Fidelity Neural Human Motion Transfer from Monocular Video ([Link](./summary/57.md))
* Big self-supervised Models are Strong Semi-supervised learners ([Link](./summary/58.md))
* NeuralRecon: Real-Time Coherent 3D Reconstruction From Monocular Video ([Link](./summary/59.md))
* Quantifying Attention Flow in Transformers ([Link](./summary/60.md))
* Repurposing GANs for One-Shot Semantic Part Segmentation ([Link](./summary/61.md))
* PIC-NET : Point Cloud and Image Collaboration Network for Large-Scale Place Recognition ([Link](./summary/62.md))
* Repurposing GANs for One-shot Semantic Part Segmentation ([Link](./summary/63.md))
* Training Generative Adversarial Networks in One Stage ([Link](./summary/64.md))
* Transformer Interpretability Beyond Attention Visualization ([Link](./summary/65.md))
* GNeRF: GAN-based Neural Radiance Field without Posed Camera ([Link](./summary/66.md))
* Exploring Simple Siamese Representation Learning ([Link](./summary/68.md))
* Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers ([Link](./summary/69.md))
* Nex: Real-time View Synthesis with Neural Basis Expansion  ([Link](./summary/70.md))
